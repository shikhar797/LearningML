{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5c5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c0abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tannushree/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading average_preception_tagger: Package\n",
      "[nltk_data]     'average_preception_tagger' not found in index\n",
      "[nltk_data] Error loading averaged_preception_tagger_eng: Package\n",
      "[nltk_data]     'averaged_preception_tagger_eng' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('average_preception_tagger')\n",
    "nltk.download('averaged_preception_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=\"\"\"\n",
    "John is an experienced software engineering with expertise in Python ,Java and SQL.\n",
    "He devlops scalable web applicaition and manages cloud infrastructure .\n",
    "His responsiblities include design algorithm ,testing and collabrabting .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9049225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower() # To convert into lowercase characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # To Remove Punctuations\n",
    "    tokens = nltk.word_tokenize(text) # Tokenizer\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118d384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=preprocess_text(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize sentences and words\n",
    "sentences=nltk.sent_tokenize(clean_text)\n",
    "tokenize_sentence=[word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged_sentences=[nltk.pos_tag(tokens) for tokens in tokenize_sentence]\n",
    "\n",
    "for i, sentence in enumerate(pos_tagged_sentences):\n",
    "    print(f\"\\n Sentence {i+1} POS Tags\")\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags=[tag for senyence in pos_tagged_sentences for (word ,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10acc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
